import numpy as np
import matplotlib.pyplot as plt

# Part (a): Projected Gradient Descent (PGD)
file = open("vectors.txt", "r")
data = file.readlines()
Nlines = len(data)

wfile = open("words_idx.txt", "r")
words = wfile.readlines()
Nwords = len(words)

Ndocs = int(Nlines / 2)
A = np.zeros((Nwords, Ndocs))

for j in range(Ndocs):
    line = data[2 * j + 1]
    line = line.split()
    numbers = [int(i) for i in line]
    w_idx = np.array(numbers[1::2]) - 1
    A[w_idx, j] = 1

k = 10
iter_max = 200
learning_rate = 0.001
num_runs = 5

fig, axs = plt.subplots(1, num_runs, figsize=(20, 5))
fig.suptitle('Projected Gradient Descent for Matrix Factorization (Multiple Runs)', fontsize=16)

for run in range(num_runs):
    W = np.random.rand(Nwords, k)
    H = np.random.rand(k, Ndocs)
    R_FroNorm = np.zeros(iter_max)

    for iter in range(iter_max):
        gradient_W = -2 * (A - W @ H) @ H.T
        gradient_H = -2 * W.T @ (A - W @ H)

        W -= learning_rate * gradient_W
        H -= learning_rate * gradient_H

        W = np.maximum(W, 0)
        H = np.maximum(H, 0)

        R = A - W @ H
        R_FroNorm[iter] = np.linalg.norm(R, 'fro')

    axs[run].plot(R_FroNorm)
    axs[run].set_title(f'Run {run + 1}')
    axs[run].set_xlabel('Iterations')
    axs[run].set_ylabel('Frobenius Norm')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

final_residual_pgd = R_FroNorm[-1]
print(f"Final Frobenius Norm of Residual (PGD): {final_residual_pgd}")

threshold = 0.5
top_n_words = 5

print("\nSignificant words in W (PGD, threshold > 0.5, limited to top 5):")
for j in range(k):
    ind = np.squeeze(np.argwhere(W[:, j] > threshold))
    if len(ind) > 0:
        sorted_indices = ind[np.argsort(-W[ind, j])]
        limited_indices = sorted_indices[:top_n_words]

        print(f"Column {j + 1}:")
        for i in limited_indices:
            print(f"  {i + 1}: {words[i].strip()}")

# Part (b): HALS Algorithm for Matrix Factorization
fig, axs = plt.subplots(1, num_runs, figsize=(20, 5))
fig.suptitle('HALS for Matrix Factorization (Multiple Runs)', fontsize=16)

for run in range(num_runs):
    W = np.random.rand(Nwords, k)
    H = np.random.rand(k, Ndocs)
    R_FroNorm_HALS = np.zeros(iter_max)

    for iter in range(iter_max):
        for j in range(k):
            H[j, :] = np.maximum(H[j, :] + (W[:, j].T @ (A - W @ H)) / (W[:, j].T @ W[:, j] + 1e-12), 0)

        for i in range(k):
            W[:, i] = np.maximum(W[:, i] + ((A - W @ H) @ H[i, :].T) / (H[i, :] @ H[i, :].T + 1e-12), 0)

        R = A - W @ H
        R_FroNorm_HALS[iter] = np.linalg.norm(R, 'fro')

    axs[run].plot(R_FroNorm_HALS)
    axs[run].set_title(f'Run {run + 1}')
    axs[run].set_xlabel('Iterations')
    axs[run].set_ylabel('Frobenius Norm')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

final_residual_hals = R_FroNorm_HALS[-1]
print(f"Final Frobenius Norm of Residual (HALS): {final_residual_hals}")

print("\nSignificant words in W (HALS, threshold > 0.5, limited to top 5):")
for j in range(k):
    ind = np.squeeze(np.argwhere(W[:, j] > threshold))
    if len(ind) > 0:
        sorted_indices = ind[np.argsort(-W[ind, j])]
        limited_indices = sorted_indices[:top_n_words]

        print(f"Column {j + 1}:")
        for i in limited_indices:
            print(f"  {i + 1}: {words[i].strip()}")

# Part (c): Best Rank-10 Approximation Using SVD
U, S, VT = np.linalg.svd(A, full_matrices=False)
U_10 = U[:, :10]
S_10 = np.diag(S[:10])
VT_10 = VT[:10, :]

A_10 = U_10 @ S_10 @ VT_10
R_SVD = A - A_10
R_SVD_norm = np.linalg.norm(R_SVD, 'fro')

print(f"Frobenius Norm of Residual (Rank-10 SVD): {R_SVD_norm}")

word_scores = np.sum(W, axis=1)
top_indices = np.argsort(-word_scores)[:top_n_words]
top_words_hals = [words[idx].strip() for idx in top_indices]

print("\nTop words overall (HALS):")
print(top_words_hals)
